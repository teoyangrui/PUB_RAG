{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "36b4ef88-cfc9-465e-bafe-2131b0258ed3",
      "metadata": {
        "id": "36b4ef88-cfc9-465e-bafe-2131b0258ed3"
      },
      "source": [
        "---\n",
        "---\n",
        "# Notebook: [ Week #04: From Embeddings to Applications]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KKnSP5uwuY2m",
      "metadata": {
        "id": "KKnSP5uwuY2m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f3277502-6fd2-4d9c-9230-e29daa52a881",
      "metadata": {
        "id": "f3277502-6fd2-4d9c-9230-e29daa52a881"
      },
      "source": [
        "## Setup\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a143147f-120f-4b88-a078-af25a976e993",
      "metadata": {
        "id": "a143147f-120f-4b88-a078-af25a976e993"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install langchain\n",
        "!pip install langchain-openai\n",
        "!pip install langchain-experimental\n",
        "!pip install pypdf\n",
        "!pip install lolviz\n",
        "!pip install chromadb\n",
        "!pip install rank_bm25\n",
        "!pip install umap-learn\n",
        "!pip install tqdm\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m7BYo0rjUfa6",
      "metadata": {
        "id": "m7BYo0rjUfa6",
        "outputId": "de05c77e-06ea-491f-dd10-10bfc850ec28"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://d17lzt44idt8rf.cloudfront.net/aicamp/data/digital_products.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf6b922c-6ba8-4f72-8505-1d9e9082d1ea",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:04:02.399355Z",
          "start_time": "2024-04-18T10:03:46.985122Z"
        },
        "id": "bf6b922c-6ba8-4f72-8505-1d9e9082d1ea",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from getpass import getpass\n",
        "\n",
        "API_KEY = getpass(\"Enter your OpenAI API Key\")\n",
        "client = OpenAI(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dedf9c9-10e2-409d-a278-c4ab11ecec20",
      "metadata": {
        "id": "4dedf9c9-10e2-409d-a278-c4ab11ecec20"
      },
      "source": [
        "## Helper Function\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "502df0ab-0070-45c7-91e0-947b67a38b6b",
      "metadata": {
        "id": "502df0ab-0070-45c7-91e0-947b67a38b6b"
      },
      "source": [
        "## Function for Generating Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38b50326-d1b2-41b6-a9e5-30ead5746975",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:04:06.378658Z",
          "start_time": "2024-04-18T10:04:06.375417Z"
        },
        "id": "38b50326-d1b2-41b6-a9e5-30ead5746975"
      },
      "outputs": [],
      "source": [
        "def get_embedding(input, model='text-embedding-3-small'):\n",
        "    response = client.embeddings.create(\n",
        "        input=input,\n",
        "        model=model\n",
        "    )\n",
        "    return [x.embedding for x in response.data]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c598843-e679-4c5c-91b0-a7d521a04529",
      "metadata": {
        "id": "9c598843-e679-4c5c-91b0-a7d521a04529"
      },
      "source": [
        "## Function for Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc43c3a5-6fd2-4959-86d2-efcb01d4e1fc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:04:07.689552Z",
          "start_time": "2024-04-18T10:04:07.686329Z"
        },
        "id": "fc43c3a5-6fd2-4959-86d2-efcb01d4e1fc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# This is the \"Updated\" helper function for calling LLM\n",
        "                                # gpt-4\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0, top_p=1.0, max_tokens=4000, n=1):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        max_tokens=max_tokens,\n",
        "        n=1\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab732b0a-d180-45b3-b157-1b5b3fb91504",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:04:12.005574Z",
          "start_time": "2024-04-18T10:04:12.003060Z"
        },
        "id": "ab732b0a-d180-45b3-b157-1b5b3fb91504"
      },
      "outputs": [],
      "source": [
        "# This a \"modified\" helper function that we will discuss in this session\n",
        "# Note that this function directly take in \"messages\" as the parameter.\n",
        "def get_completion_by_messages(messages, model=\"gpt-3.5-turbo\", temperature=0, top_p=1.0, max_tokens=1024, n=1):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        max_tokens=max_tokens,\n",
        "        n=1\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea754f8c-dda7-44d9-a23f-9d670a0b8d58",
      "metadata": {
        "id": "ea754f8c-dda7-44d9-a23f-9d670a0b8d58"
      },
      "source": [
        "## Functions for Token Counting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a41d37f-2bba-4c5c-beae-9fe160785cfa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:04:16.628901Z",
          "start_time": "2024-04-18T10:04:15.654851Z"
        },
        "id": "4a41d37f-2bba-4c5c-beae-9fe160785cfa"
      },
      "outputs": [],
      "source": [
        "# This function is for calculating the tokens given the \"message\"\n",
        "# ⚠️ This is simplified implementation that is good enough for a rough estimation\n",
        "\n",
        "import tiktoken\n",
        "\n",
        "def count_tokens(text):\n",
        "    encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "def count_tokens_from_message_rough(messages):\n",
        "    encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
        "    value = ' '.join([x.get('content') for x in messages])\n",
        "    return len(encoding.encode(value))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48c0d11c-3cb5-44b1-806d-8ae6a467ba4f",
      "metadata": {
        "id": "48c0d11c-3cb5-44b1-806d-8ae6a467ba4f"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e35403a7-628d-4128-8967-ce0290992e7f",
      "metadata": {
        "id": "e35403a7-628d-4128-8967-ce0290992e7f"
      },
      "source": [
        "# Understanding Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e01b046a-b5c8-43d4-bc3e-1c8fd8dfe202",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:04:19.489871Z",
          "start_time": "2024-04-18T10:04:19.487443Z"
        },
        "id": "e01b046a-b5c8-43d4-bc3e-1c8fd8dfe202"
      },
      "outputs": [],
      "source": [
        "in_1 = \"Flamingo spotted at the in the bird park\"\n",
        "\n",
        "in_2 = \"Sea otter seen playing at the marine park\"\n",
        "\n",
        "in_3 = \"Baby panda born at the city zoo\"\n",
        "\n",
        "in_4 = \"Python developers prefer snake_case for variable naming\"\n",
        "\n",
        "in_5 = \"New JavaScript framework aims to simplify coding\"\n",
        "\n",
        "in_6 = \"C++ developers appreciate the power of OOP\"\n",
        "\n",
        "in_7 = \"Java is a popular choice for enterprise applications\"\n",
        "\n",
        "\n",
        "list_of_input_texts = [in_1, in_2, in_3, in_4, in_5, in_6, in_7]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a7a40cd-a3c8-497e-ab0d-494bfaaa3002",
      "metadata": {
        "id": "9a7a40cd-a3c8-497e-ab0d-494bfaaa3002"
      },
      "source": [
        "## Understand the Outputs of Embedding Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4abccc0-ff2f-40f5-bac4-a947ce819885",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:04:22.872152Z",
          "start_time": "2024-04-18T10:04:21.360377Z"
        },
        "id": "c4abccc0-ff2f-40f5-bac4-a947ce819885"
      },
      "outputs": [],
      "source": [
        "response = get_embedding(list_of_input_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "438388f2-54ae-48e9-ba11-72e20b968206",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:04:22.877256Z",
          "start_time": "2024-04-18T10:04:22.872152Z"
        },
        "id": "438388f2-54ae-48e9-ba11-72e20b968206"
      },
      "outputs": [],
      "source": [
        "len(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69376e4c-bba4-483b-b728-27154e6e13aa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:04:24.377480Z",
          "start_time": "2024-04-18T10:04:24.374347Z"
        },
        "id": "69376e4c-bba4-483b-b728-27154e6e13aa"
      },
      "outputs": [],
      "source": [
        "len(response[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5f435a1-0e7b-4f42-85e1-e45d6bddf0f4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:04:40.045163Z",
          "start_time": "2024-04-18T10:04:36.517799Z"
        },
        "id": "a5f435a1-0e7b-4f42-85e1-e45d6bddf0f4"
      },
      "outputs": [],
      "source": [
        "import lolviz\n",
        "\n",
        "lolviz.objviz(response)\n",
        "\n",
        "# Note that there are 7 items in the list, each represents the embeddings (list of numerical values) for each of the inputs\n",
        "# Each embedding vector contains 1,536 numerical values that represent the original text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05758d1b-38e8-4573-827c-bc03d41b814e",
      "metadata": {
        "id": "05758d1b-38e8-4573-827c-bc03d41b814e"
      },
      "outputs": [],
      "source": [
        "# To Save the image locally\n",
        "# Supported format includes svg, png, jpeg, pdf, and etc.\n",
        "drawing.render('embeddings_seven', format='png')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5a7df03-6a1a-46d6-bb59-aa564e748782",
      "metadata": {
        "id": "f5a7df03-6a1a-46d6-bb59-aa564e748782"
      },
      "source": [
        "## Visualize Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6402060c-e174-4c5f-8564-a14df5547d85",
      "metadata": {
        "id": "6402060c-e174-4c5f-8564-a14df5547d85"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de21b451-5953-4e5b-9192-c0dbbd9f42a5",
      "metadata": {
        "id": "de21b451-5953-4e5b-9192-c0dbbd9f42a5"
      },
      "source": [
        "### Understanding UMAP for Data Analysts\n",
        "\n",
        "- Uniform Manifold Approximation and Projection (UMAP) is a powerful dimensionality reduction technique that can be used to visualize high-dimensional data in a lower-dimensional space.\n",
        "- Unlike other dimensionality reduction techniques, UMAP preserves both the local and global structure of the data, making it an excellent tool for exploratory data analysis.\n",
        "\n",
        "### Using UMAP in Python\n",
        "\n",
        "The UMAP algorithm is implemented in the `umap-learn` package in Python. Here's a simple example of how to use it:\n",
        "\n",
        "```python\n",
        "import umap\n",
        "import numpy as np\n",
        "\n",
        "# Assume embeddings is your high-dimensional data\n",
        "embeddings = np.random.rand(100, 50)\n",
        "\n",
        "reducer = umap.UMAP()\n",
        "umap_embeddings = reducer.fit_transform(embeddings)\n",
        "```\n",
        "\n",
        "In this example, `umap.UMAP()` creates a UMAP object, and `fit_transform()` fits the model to the data and then transforms the data to a lower-dimensional representation. The result, `umap_embeddings`, is a 2D array of the lower-dimensional embeddings of your data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c2939a4-4857-4cda-84a6-545ee60107bf",
      "metadata": {
        "id": "1c2939a4-4857-4cda-84a6-545ee60107bf"
      },
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "In this following example, we will use UMAP to visualize the 7 pieces of texts from the previous example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44dc8898-eac1-4f75-99ed-c71e9bdbb71c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:07:33.930685Z",
          "start_time": "2024-04-18T10:07:01.618167Z"
        },
        "id": "44dc8898-eac1-4f75-99ed-c71e9bdbb71c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import umap # For compressing high-dimensional data (many columns) into lower-dimensional data (e.g. 2 columns)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # For data visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adba5580-ea80-4014-a25b-9b03ffc96a9b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:08:05.571378Z",
          "start_time": "2024-04-18T10:08:05.568660Z"
        },
        "id": "adba5580-ea80-4014-a25b-9b03ffc96a9b"
      },
      "outputs": [],
      "source": [
        "def get_projected_embeddings(embeddings, random_state=0):\n",
        "    reducer = umap.UMAP(random_state=random_state).fit(embeddings)\n",
        "    embeddings_2d_array = reducer.transform(embeddings)\n",
        "    return pd.DataFrame(embeddings_2d_array, columns=['x', 'y'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc7529044dd3fce3",
      "metadata": {
        "id": "bc7529044dd3fce3"
      },
      "source": [
        "> 💡 Explanation for the cell above:\n",
        "> - `def get_projected_embeddings(embeddings, random_state=0):` This line defines the function and its parameters. The function takes in two arguments: embeddings (your high-dimensional data) and random_state (a seed for the random number generator, which ensures that the results are reproducible).  \n",
        "> - `reducer = umap.UMAP(random_state=random_state).fit(embeddings)` This line creates a UMAP object and fits it to your data. The fit method learns the structure of the data.  \n",
        "> - `embeddings_2d_array = reducer.transform(embeddings)` This line transforms the high-dimensional data into a lower-dimensional space. The transformed data is stored in embeddings_2d_array.  \n",
        "> - `return pd.DataFrame(embeddings_2d_array, columns=['x', 'y'])` This line converts the lower-dimensional data into a pandas DataFrame for easier manipulation and returns it. The DataFrame has two columns, 'x' and 'y', which represent the two dimensions of the reduced data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9fe0796-a56f-48bc-8d38-08eb1151c610",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:10:35.339543Z",
          "start_time": "2024-04-18T10:10:31.247888Z"
        },
        "id": "e9fe0796-a56f-48bc-8d38-08eb1151c610"
      },
      "outputs": [],
      "source": [
        "# Get the embeddings in a DataFrame object\n",
        "projected_embeddings = get_projected_embeddings(response)\n",
        "\n",
        "# Insert a new column to store the original texts\n",
        "projected_embeddings['text'] = list_of_input_texts\n",
        "\n",
        "projected_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fd93637-e5c9-4f06-a633-4056c99dcec3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:10:46.570755Z",
          "start_time": "2024-04-18T10:10:45.970489Z"
        },
        "id": "5fd93637-e5c9-4f06-a633-4056c99dcec3",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create the Scatter plot that visualize the locations of the embeddings in the number space (commonly known as \"vector space\")\n",
        "sns.scatterplot(x=projected_embeddings['x'], y=projected_embeddings['y'])\n",
        "\n",
        "# Add labels to each point\n",
        "for i in range(projected_embeddings.shape[0]):\n",
        "    plt.text(x=projected_embeddings.loc[i, 'x'],\n",
        "             y=projected_embeddings.loc[i, 'y'],\n",
        "             s=projected_embeddings.loc[i, 'text'],\n",
        "             fontsize='x-small')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88c763db-f8fc-453c-b3c5-d8de4173209d",
      "metadata": {
        "id": "88c763db-f8fc-453c-b3c5-d8de4173209d"
      },
      "source": [
        "- Observe the distances between the different texts\n",
        "  - Although the text starts with \"Python developers prefer snake_case\", contains two animals, the embedding is further away from the three data points that truly talking about animals.\n",
        "  - It is closer to the other two data points that are focusing on programming/coding\n",
        "\n",
        "![](https://d17lzt44idt8rf.cloudfront.net/aicamp/resources/embeddings_distance.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88fafc46-68d9-4d76-80fa-e364fc5a5650",
      "metadata": {
        "id": "88fafc46-68d9-4d76-80fa-e364fc5a5650"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95a34587-c504-4de6-b322-a315b79f8a9a",
      "metadata": {
        "id": "95a34587-c504-4de6-b322-a315b79f8a9a"
      },
      "source": [
        "\n",
        "### Understanding Cosine Similarity for LLM Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6e05896-f5d4-458b-b953-7b1c5cccedfd",
      "metadata": {
        "id": "c6e05896-f5d4-458b-b953-7b1c5cccedfd"
      },
      "source": [
        "Cosine similarity is a metric used to measure how similar two vectors are, irrespective of their size. It's widely used in natural language processing to calculate the similarity between text documents represented as vector embeddings, such as those produced by Language Learning Models (LLMs).\n",
        "\n",
        "The cosine similarity between two vectors is calculated as the cosine of the angle between them.\n",
        "- If the vectors are identical, the angle is 0 and the cosine similarity is 1.\n",
        "- If the vectors are orthogonal, the angle is 90 degrees and the cosine similarity is 0, indicating no similarity.\n",
        "\n",
        "Cosine similarity is particularly useful for LLM embeddings because it effectively captures the semantic similarity between text documents. It's robust to the high dimensionality of LLM embeddings and is relatively efficient to compute, making it a popular choice for measuring the distance between LLM embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683c05f1-8205-48d5-9424-fc62e6f88541",
      "metadata": {
        "id": "683c05f1-8205-48d5-9424-fc62e6f88541"
      },
      "source": [
        "---\n",
        "---\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b61200f-df27-4a09-8263-56b9a430cf2c",
      "metadata": {
        "id": "5b61200f-df27-4a09-8263-56b9a430cf2c"
      },
      "source": [
        "# Setting up Credentials for langchain\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5345ec3e-d2ee-43b3-a8c5-1166af6e2ec3",
      "metadata": {
        "id": "5345ec3e-d2ee-43b3-a8c5-1166af6e2ec3"
      },
      "source": [
        "We will be using `Langchain` for our Use Cases in the next section.\n",
        "- The code cell below is to set up the credentials (i.e., the OPENAI API KEY) to allow `Langchain` to use OpenAI API Endpoints,\n",
        "such as the `ChatCompletion` and `Embedding`.\n",
        "- This also means that we will not directly use OpenAI's SDK in some of the use cases below.\n",
        "- `Langchain`'s components like those `retriever` (that we discussed in the Knowledge Base) will handle the API calls to OpenAI's API endpoints automatically. All we need to do is to specify the `API_KEY` as required by Langchain, as indicated in the cell below.\n",
        "- This way of providing credentials is called `environment variable assignment` or `setting environment variable`\n",
        "- Specifically, it sets the value of the environment variable named `OPENAI_API_KEY` to the value stored in the Python variable `API_KEY` (we entered earlier in this notebook).\n",
        "- Environment variables are used to configure and customize the behavior of software applications by allowing them to access external settings or secrets without hardcoding them directly into the code.\n",
        "- We will learn more about setting the credentials  more efficiency and securly in later part of our training.\n",
        "\n",
        "Find out more about why we are using Langchain from [here](https://d27l3jncscxhbx.cloudfront.net/topic-4-from-embeddings-to-applications/4.-retrieval-augmented-generation-(rag).html#Using_Langchain_for_RAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67cbb04f-6064-459e-8e82-edb394d8f473",
      "metadata": {
        "id": "67cbb04f-6064-459e-8e82-edb394d8f473"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_VERSION\"] = \"2024-03-01-preview\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c839ecb-894a-44b8-81b5-3d04a5ab6f83",
      "metadata": {
        "id": "3c839ecb-894a-44b8-81b5-3d04a5ab6f83",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6237d78e-11a9-4bc7-846b-fb3b80493719",
      "metadata": {
        "id": "6237d78e-11a9-4bc7-846b-fb3b80493719"
      },
      "source": [
        "# Use Cases of Embeddings\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5c90f1c-3eba-4185-a6f4-200434fd9a11",
      "metadata": {
        "id": "e5c90f1c-3eba-4185-a6f4-200434fd9a11"
      },
      "source": [
        "## Use Case #1: Semantic Search & Recommendation System"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c135ee0-b0bc-4f3a-85c7-a7efcd7f758d",
      "metadata": {
        "id": "2c135ee0-b0bc-4f3a-85c7-a7efcd7f758d"
      },
      "source": [
        "### Understanding Keyword Retrieval and Dense Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e45cdd84-7cb9-4289-ae72-442e02625a78",
      "metadata": {
        "id": "e45cdd84-7cb9-4289-ae72-442e02625a78"
      },
      "source": [
        "- Keyword retrieval and dense retrieval are two different methods used in information retrieval systems.\n",
        "\n",
        "- Keyword Retrieval:\n",
        "    - Keyword retrieval, also known as sparse retrieval, is a traditional method of information retrieval.\n",
        "    - It involves matching the exact keywords in the query with the documents in the database.\n",
        "    - This method is simple and explainable, but it has some limitations\n",
        "    - It doesn’t fully capture the semantics of each term in the context of the whole text.\n",
        "    - It may not perform well when the query words do not exactly match the words in the document.\n",
        "- Dense Retrieval (or Semantic Search):\n",
        "    - Dense retrieval, on the other hand, uses dense vector representations (embeddings) of the text to capture the deep semantic relationship between queries and documents.\n",
        "    - These vectors are usually generated by neural networks, particularly transformer-based models.\n",
        "    - This method shows a huge improvement over keyword search as it captures the semantics of the text1. However, it’s more complex and computationally intensive than keyword retrieval.\n",
        "\n",
        "<br>\n",
        "    \n",
        "- Here are the key differences between the two methods:\n",
        "    - **Semantics**: Dense retrieval captures the semantics of the text, while keyword retrieval does not.\n",
        "    - **Matching**: Keyword retrieval relies on exact keyword matching, while dense retrieval uses semantic matching.\n",
        "    - **Performance**: Dense retrieval generally outperforms keyword retrieval, especially when the query words do not exactly match the words in the document.\n",
        "    - **Complexity**: Dense retrieval is more complex and computationally intensive than keyword retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02000dcd-fc56-4dcb-ba09-ebd08fe0f071",
      "metadata": {
        "id": "02000dcd-fc56-4dcb-ba09-ebd08fe0f071"
      },
      "source": [
        "[Reference for Products - https://www.developer.tech.gov.sg/products/all-products/](https://www.developer.tech.gov.sg/products/all-products/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d451814-1478-4abf-9d33-1d1debe4216d",
      "metadata": {
        "id": "9d451814-1478-4abf-9d33-1d1debe4216d"
      },
      "outputs": [],
      "source": [
        "# The variable `corpus`  contains a list of documents (text data).\n",
        "# We are using the products & services from Reference https://www.developer.tech.gov.sg/products/all-products/\n",
        "corpus = [\n",
        "    'Cybersecurity. AI Document Parser (AISAY) – An AI-Powered Document Reader and Transcription API Service. AISAY is an AI-Powered Document Reader and Transcription API Service for public officers. Learn more here!',\n",
        "    'Analytics. Analytics.gov – Enabling Data Exploitation for Whole-of-Government (WOG). Analytics.gov is a Whole-Of-Government (WOG) data exploitation platform to support the analysis of data by agencies.',\n",
        "    'Productivity. Cloak – The Central Privacy Toolkit for Policy-Compliant Data Anonymisation. Cloak helps public officers to anonymise sensitive data based on public sector guidelines through a one-stop, self-service web application. Learn more here!',\n",
        "    'DevOps. Container Stack (CStack) – Managed Platform for Apps using Kubernetes. Container Stack is a cloud-based container hosting platform and a Runtime component within Singapore Government Tech Stack.',\n",
        "    'Data and APIs. Data.gov.sg — The One-Stop Open Data Portal for Publicly Available Singapore Government Datasets. Learn from Data.gov.sg, Singapore’s one-stop open data portal offering government datasets. Dive in now!',\n",
        "    'Analytics. GovText – The Whole-of-Government Text Analytics Platform. Analyse your textual data efficiently with the GovText Natural Language Processing (NLP) platform for WOG. Discover more!',\n",
        "    'Data and APIs. Monetary Authority of Singapore (MAS) APIs - Streamlining of Financial Applications through Data. The Monetary Authority of Singapore (MAS) provides APIs for developers, allowing MAS’ applications to be streamlined.',\n",
        "    'Analytics. Whole-of-Government Application Analytics (WOGAA) - Improve Government Services with Data. WOGAA is an analytics & performance platform for public officers to monitor the health of their government websites and optimise the performance of their digital services with data.',\n",
        "    'Data and APIs. Vault - A Central Data Discovery and Distribution Platform for WOG Vault is a platform where government data is consolidated, organised and made discoverable for public servants to explore, search and securely access.',\n",
        "    'Productivity. Transcribe provides auto-transcription and localised Speech-to-Text services for Singapore government officers.',\n",
        "    'Data and APIs. SingStat Table Builder. The SingStat Table Builder contains over 1,800 statistical data tables from 60 public sector agencies providing a comprehensive statistical view of Singapore’s economic and socio-demographic characteristics.',\n",
        "    'Productivity. Postman — Deliver Messages to Citizens in Minutes. Postman is a multichannel cloud-based service for Singapore government agencies to send mass personalized messages in minutes.',\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "119034ab-42fe-4eb7-b402-402369b30c40",
      "metadata": {
        "id": "119034ab-42fe-4eb7-b402-402369b30c40"
      },
      "source": [
        "#### Keywords Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae178dbd-1031-471c-9a9c-b92e05df0585",
      "metadata": {
        "id": "ae178dbd-1031-471c-9a9c-b92e05df0585"
      },
      "outputs": [],
      "source": [
        "# This library provides an implementation of the BM25 algorithm,\n",
        "# which is commonly used for information retrieval and text search\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# Tokenizes each document in the corpus\n",
        "# by splitting it into individual words based on spaces.\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "\n",
        "# Initialize BM25\n",
        "# The BM25Okapi model is now ready to compute relevance scores for queries against this corpus.\n",
        "bm25 = BM25Okapi(tokenized_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78873b2c-a849-4ff9-a4e7-4a4903661302",
      "metadata": {
        "id": "78873b2c-a849-4ff9-a4e7-4a4903661302"
      },
      "outputs": [],
      "source": [
        "# Now let's say we have the following query\n",
        "query = \"Data exploitation\"\n",
        "\n",
        "# The query is tokenized into individual words: tokenized_query = query.split(\" \")\n",
        "# The query must be tokenized in the same way as the corpus (list of input documents)\n",
        "tokenized_query = query.split(\" \")\n",
        "\n",
        "# Computes BM25 scores for each document in the corpus based on the query.\n",
        "doc_scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "# Print the list of relevance scores corresponding to each document.\n",
        "# It's  a position (index) based listing of the score,\n",
        "# based on the original order of the text in our `corpus` variable\n",
        "print(doc_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed51c053-7513-4cce-86de-f4d137945e66",
      "metadata": {
        "id": "ed51c053-7513-4cce-86de-f4d137945e66"
      },
      "outputs": [],
      "source": [
        "# Finding the Most Relevant Document:\n",
        "import numpy as np\n",
        "x = np.array(doc_scores)\n",
        "\n",
        "# The argmax() function returns the index of the maximum value in the array.\n",
        "# This line use \"indexing\" apprach to retrieve the most relevant document\n",
        "# from the original corpus based on the highest BM25 scores.\n",
        "corpus[x.argmax()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2942c9c0-3bbf-43db-9b29-dc060774375a",
      "metadata": {
        "id": "2942c9c0-3bbf-43db-9b29-dc060774375a"
      },
      "source": [
        "> 💡 Experiemnt with different `query` to see how well the `Keyword-based Retriever` works and when does it hit its limitations\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "567e67e4-7e81-41cd-825d-c9ed88966e05",
      "metadata": {
        "id": "567e67e4-7e81-41cd-825d-c9ed88966e05"
      },
      "source": [
        "> ⚠️ The provided code demonstrates a basic implementation of the BM25 algorithm for keyword-based search.\n",
        "> - However, it’s essential to recognize that real-world production-level keyword search systems are significantly more complex.\n",
        "> - While this simplified BM25 example provides a foundational understanding, building robust search systems involves addressing these complexities.\n",
        "> - Production-level search engines require a combination of information retrieval, machine learning, and engineering expertise to deliver accurate and efficient results.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "320dc4cd-2963-467a-b9ef-9fe27805e943",
      "metadata": {
        "id": "320dc4cd-2963-467a-b9ef-9fe27805e943"
      },
      "source": [
        "#### Dense Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4ffb128-16d3-4c1f-9c4b-072de063f7fd",
      "metadata": {
        "id": "c4ffb128-16d3-4c1f-9c4b-072de063f7fd"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fccf8b2a-e6b2-4ee2-89c9-756a7c7ad489",
      "metadata": {
        "id": "fccf8b2a-e6b2-4ee2-89c9-756a7c7ad489"
      },
      "outputs": [],
      "source": [
        "query = \"Data exploitation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2148e2a-34e0-4f2d-8dd9-c5e15ce2de1c",
      "metadata": {
        "id": "c2148e2a-34e0-4f2d-8dd9-c5e15ce2de1c"
      },
      "outputs": [],
      "source": [
        "# an embeddings model is initialized using the OpenAIEmbeddings class.\n",
        "# The specified model is 'text-embedding-3-small'.\n",
        "embeddings_model = OpenAIEmbeddings(model='text-embedding-3-small')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "959d0dc8-cf15-4fd1-ba9a-86c7dd350b9a",
      "metadata": {
        "id": "959d0dc8-cf15-4fd1-ba9a-86c7dd350b9a"
      },
      "outputs": [],
      "source": [
        "# A vector store (also known as a database) is created using the Chroma class.\n",
        "# It stores embeddings for a given set of texts (documents).\n",
        "# The embeddings_model is used to convert the texts into embeddings.\n",
        "vectorstore = Chroma.from_texts(corpus, embeddings_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "045c7add-9773-420e-92e2-149fd46a2162",
      "metadata": {
        "id": "045c7add-9773-420e-92e2-149fd46a2162"
      },
      "outputs": [],
      "source": [
        "# This line performs a similarity search within the vector store for the query\n",
        "# The k=3 parameter specifies that we want to retrieve the top 3 most similar documents.\n",
        "# The method returns both the similar documents and their associated relevance scores.\n",
        "# These scores indicate how similar each retrieved document is to the query (higher value means highly similar).\n",
        "vectorstore.similarity_search_with_relevance_scores(query, k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d16ca2f-e65a-476f-9564-dfcc6d419bf9",
      "metadata": {
        "id": "5d16ca2f-e65a-476f-9564-dfcc6d419bf9"
      },
      "source": [
        "> 💡 Experiemnt with different `query` to see how well the `Keyword-based Retriever` works on vague query and non-direct match\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d897684-2e1f-402d-82d1-c9d5bf7377ed",
      "metadata": {
        "id": "3d897684-2e1f-402d-82d1-c9d5bf7377ed"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "bc881409-e987-41fc-aab6-9e2761236473",
      "metadata": {
        "id": "bc881409-e987-41fc-aab6-9e2761236473"
      },
      "source": [
        "## Use Case #2: Building Predictive Models with Semantic Meanings of Text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99e15ca4-78e1-4f54-832a-c57441387bbb",
      "metadata": {
        "id": "99e15ca4-78e1-4f54-832a-c57441387bbb"
      },
      "source": [
        "---\n",
        "\n",
        "We are preparing the data for our machine learning model later,\n",
        "where we want to use the \"description of the product\" to derive at the classification of the products\n",
        "e.g., is it `productivity`, `cybersecurity`, `analytics` or other categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "inQZn67k0TJW",
      "metadata": {
        "id": "inQZn67k0TJW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e53e3fbf-0533-4937-a004-c29c3bacf3f9",
      "metadata": {
        "id": "e53e3fbf-0533-4937-a004-c29c3bacf3f9"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"digital_products.csv\")\n",
        "df[-10:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d46adcfb-8b02-43db-870c-47868134e8a2",
      "metadata": {
        "id": "d46adcfb-8b02-43db-870c-47868134e8a2"
      },
      "outputs": [],
      "source": [
        "# Get the embeddings of the \"description\" (text column)\n",
        "embeddings_vector_prods = get_embedding(df.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "188e1f57-cab5-4daa-bac1-96bf402ebc91",
      "metadata": {
        "id": "188e1f57-cab5-4daa-bac1-96bf402ebc91"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9b9851b-c330-4e17-907f-d6c6fbb22d06",
      "metadata": {
        "id": "b9b9851b-c330-4e17-907f-d6c6fbb22d06"
      },
      "outputs": [],
      "source": [
        "# Split your data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(embeddings_vector_prods, df.label, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0f8d316-cab6-47f3-977f-797dd3bcaec6",
      "metadata": {
        "id": "d0f8d316-cab6-47f3-977f-797dd3bcaec6"
      },
      "outputs": [],
      "source": [
        "# Choose a model\n",
        "classifier = RandomForestClassifier(max_depth=3, n_estimators=100, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "486ebc7f-6211-409b-9671-ea367867b01f",
      "metadata": {
        "id": "486ebc7f-6211-409b-9671-ea367867b01f"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eb98c54-82be-4494-a6ae-f64e2baa0c5d",
      "metadata": {
        "id": "8eb98c54-82be-4494-a6ae-f64e2baa0c5d"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2050bb6-c261-44f4-bf09-246b4be8dc30",
      "metadata": {
        "id": "e2050bb6-c261-44f4-bf09-246b4be8dc30"
      },
      "outputs": [],
      "source": [
        "# Print out the Accuracy of the Model\n",
        "# in predicting the \"cateogry of the products'\n",
        "print(accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14723d1e-a731-4586-a135-45f5346ca304",
      "metadata": {
        "id": "14723d1e-a731-4586-a135-45f5346ca304"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b277698-0d1c-471f-ab66-9688c59075c0",
      "metadata": {
        "id": "7b277698-0d1c-471f-ab66-9688c59075c0"
      },
      "source": [
        "## Use Case #3: Retrieval-Augmented Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01d0b1d6-fd8c-4ddf-8190-fac5b1f67ee8",
      "metadata": {
        "id": "01d0b1d6-fd8c-4ddf-8190-fac5b1f67ee8"
      },
      "source": [
        "**\\[ Why Context Augmentation? \\]**\n",
        "\n",
        "- LLMs offer a natural language interface between humans and data. Widely available models come pre-trained on huge amounts of publicly available data like Wikipedia, mailing lists, textbooks, source code and more.\n",
        "\n",
        "- However, while LLMs are trained on a great deal of data, they are not trained on your data, which may be private or specific to the problem you’re trying to solve. It’s behind APIs, in SQL databases, or trapped in PDFs and slide decks.\n",
        "\n",
        "- You may choose to fine-tune a LLM with your data, but:\n",
        "    - Training a LLM is expensive.\n",
        "    - Due to the cost to train, it’s hard to update a LLM with latest information.\n",
        "    - Observability is lacking. When you ask a LLM a question, it’s not obvious how the LLM arrived at its answer.\n",
        "\n",
        "- Instead of fine-tuning, one can use a context augmentation pattern called Retrieval-Augmented Generation (RAG) to obtain more accurate text generation relevant to your specific data. RAG involves the following high level steps:\n",
        "\n",
        "    1. Retrieve information from your data sources first,\n",
        "    2. Add it to your question as context, and\n",
        "    3. Ask the LLM to answer based on the enriched prompt.\n",
        "\n",
        "- In doing so, RAG overcomes all three weaknesses of the fine-tuning approach:\n",
        "    - There’s no training involved, so it’s cheap.\n",
        "    - Data is fetched only when you ask for them, so it’s always up to date.\n",
        "    - LlamaIndex can show you the retrieved documents, so it’s more trustworthy.\n",
        "\n",
        "\n",
        "**\\[ Why LangChain for Context Augmentation? \\]**\n",
        "\n",
        "- Firstly, LangChain imposes no restriction on how you use LLMs. You can still use LLMs as auto-complete, chatbots, semi-autonomous agents, and more (see Use Cases on the left). It only makes LLMs more relevant to you.\n",
        "\n",
        "- LangChain provides the following tools to help you quickly stand up production-ready RAG systems:\n",
        "\n",
        "- Data connectors ingest your existing data from their native source and format. These could be APIs, PDFs, SQL, and (much) more.\n",
        "\n",
        "- Data indexes structure your data in intermediate representations that are easy and performant for LLMs to consume.\n",
        "\n",
        "- Engines provide natural language access to your data. For example:\n",
        "\n",
        "- Query engines are powerful retrieval interfaces for knowledge-augmented output."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36ed30cb-0680-4087-8abd-9820973d9b41",
      "metadata": {
        "id": "36ed30cb-0680-4087-8abd-9820973d9b41"
      },
      "source": [
        "![](https://d27l3jncscxhbx.cloudfront.net/lib/media/img-20240421132947558.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac353cf7-682d-4f7e-ac78-af2dbd8bc59c",
      "metadata": {
        "id": "ac353cf7-682d-4f7e-ac78-af2dbd8bc59c"
      },
      "source": [
        "### Document Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "946a4a1a-8d48-46a5-8c9a-4981ddc9fe68",
      "metadata": {
        "id": "946a4a1a-8d48-46a5-8c9a-4981ddc9fe68"
      },
      "source": [
        "- Use document loaders to load data from a source as Document's.\n",
        "  - A Document is a piece of text and associated metadata.\n",
        "  - For example, there are document loaders for loading a simple .txt file, for loading the text contents of any web page, or even for loading a transcript of a YouTube video.\n",
        "\n",
        "- See [official documentation on LangChain's Document Loaders](https://python.langchain.com/docs/modules/data_connection/document_loaders) for different kinds of loaders for different sources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72527ff4-3336-4a56-9a93-cb340b2aa19b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:14:46.575607Z",
          "start_time": "2024-04-18T10:14:43.907642Z"
        },
        "id": "72527ff4-3336-4a56-9a93-cb340b2aa19b"
      },
      "outputs": [],
      "source": [
        "# In this example, we will load the Prompt Engineering Playbook\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"https://www.developer.tech.gov.sg/products/collections/data-science-and-artificial-intelligence/playbooks/prompt-engineering-playbook-beta-v3.pdf\")\n",
        "pages = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50fed09a-eb25-48fa-a9d4-74fa83107398",
      "metadata": {
        "id": "50fed09a-eb25-48fa-a9d4-74fa83107398"
      },
      "source": [
        "- Each page is a `Document` object.\n",
        "- A `Document` contains text (`page_content`) and `metadata`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ecd7b5b-da42-4e2f-911f-86c51ed3e3db",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:14:49.480517Z",
          "start_time": "2024-04-18T10:14:49.477210Z"
        },
        "id": "4ecd7b5b-da42-4e2f-911f-86c51ed3e3db"
      },
      "outputs": [],
      "source": [
        "pages[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "919a4715-c0fd-4787-a33a-f3fd894eba95",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:14:51.062697Z",
          "start_time": "2024-04-18T10:14:51.058356Z"
        },
        "id": "919a4715-c0fd-4787-a33a-f3fd894eba95"
      },
      "outputs": [],
      "source": [
        "pages[0].metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65ea21d6-ab0e-42ff-9eb7-2815ccc3d1bd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:14:54.729619Z",
          "start_time": "2024-04-18T10:14:52.174249Z"
        },
        "id": "65ea21d6-ab0e-42ff-9eb7-2815ccc3d1bd"
      },
      "outputs": [],
      "source": [
        "# Let's count how many token are there\n",
        "# by summing all the token counts from every page\n",
        "# Don't worry about understand the code in this cell\n",
        "import numpy as np\n",
        "\n",
        "list_of_tokencounts = []\n",
        "for page in pages:\n",
        "    list_of_tokencounts.append(count_tokens(page.page_content))\n",
        "\n",
        "print(f\"There are total of {np.sum(list_of_tokencounts)} tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "650a87e4-4340-468b-91bf-658f535f5ddc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:15:00.626719Z",
          "start_time": "2024-04-18T10:15:00.623806Z"
        },
        "id": "650a87e4-4340-468b-91bf-658f535f5ddc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "176bc808-1e13-4cb5-9270-a62b00d2840e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:15:04.884820Z",
          "start_time": "2024-04-18T10:15:04.880352Z"
        },
        "id": "176bc808-1e13-4cb5-9270-a62b00d2840e"
      },
      "outputs": [],
      "source": [
        "np.average(list_of_tokencounts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34fd8495-8a27-4b9f-9159-66ea421c48c0",
      "metadata": {
        "id": "34fd8495-8a27-4b9f-9159-66ea421c48c0"
      },
      "source": [
        "### Document Splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d33c8a4-43a1-4332-b041-87df378a88df",
      "metadata": {
        "id": "8d33c8a4-43a1-4332-b041-87df378a88df"
      },
      "source": [
        "![](https://d27l3jncscxhbx.cloudfront.net/lib/media/img-20240421143533502.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4da42867-84fb-4503-83be-c1b00cdf5a5b",
      "metadata": {
        "id": "4da42867-84fb-4503-83be-c1b00cdf5a5b"
      },
      "source": [
        "**[ Different Types of Spliters ]**\n",
        "- `CharacterTextSplitter()` ->Implementation Of splitting text that looks at characters.\n",
        "- `MarkdownHeaderTextSplitter()` -> lmplementation Of splitting markdown files based on specified headers.\n",
        "- `TokenTextSplitter()` -> lmplementation Of splitting text that looks at tokens.\n",
        "- `SentenceTransformersTokenTextSpIitter()`  -> lmplementation Ofsplitting text that IOOks at tO kens.\n",
        "- `RecursiveCharacterTextSplitted()`  -> lmplementation Of splitting textthat looks at characters. Recursively tries tO split by differentcha racters to find one that works.\n",
        "- `Language()` -> for CPP，Python， Ruby，Markdown, etc\n",
        "- `NLTKTextSpIitter()` -> lmplementation Of splitting text that | 00 ks atsentences using NLTK (Natural l-anguage TOOI Kit)\n",
        "- `SpacyTextSplitter()` -> lmplementation Of splitting text that IOOks atsentences using Spacy\n",
        "\n",
        "|    Name   |               Splits On               | Adds Metadata |                                                                                        Description                                                                                       |\n",
        "|:---------:|:-------------------------------------:|:-------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n",
        "| Recursive | A list of user defined characters     |               | Recursively splits text. Splitting text recursively serves the purpose of trying to keep related pieces of text next to each other. This is the recommended way to start splitting text. |\n",
        "| HTML      | HTML specific characters              | ✅             | Splits text based on HTML-specific characters. Notably, this adds in relevant information about where that chunk came from (based on the HTML)                                           |\n",
        "| Markdown  | Markdown specific characters          | ✅             | Splits text based on Markdown-specific characters. Notably, this adds in relevant information about where that chunk came from (based on the Markdown)                                   |\n",
        "| Code      | Code (Python, JS) specific characters |               | Splits text based on characters specific to coding languages. 15 different languages are available to choose from.                                                                       |\n",
        "| Token     | Tokens                                |               | Splits text on tokens. There exist a few different ways to measure tokens.                                                                                                               |\n",
        "| Character | A user defined character              |               | Splits text based on a user defined character. One of the simpler methods.                                                                                                               |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3920473-e640-49fa-9342-ca7dc90fec4f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:15:12.537415Z",
          "start_time": "2024-04-18T10:15:12.519781Z"
        },
        "id": "c3920473-e640-49fa-9342-ca7dc90fec4f"
      },
      "outputs": [],
      "source": [
        "# Basic Document Splitting\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "\n",
        "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
        "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
        "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
        "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
        "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
        "Sentences have a period at the end, but also, have a space.\\\n",
        "and words are separated by space.\"\"\"\n",
        "\n",
        "\n",
        "# Splitting the text: The split_text method of the r_splitter object is called with some_text as the argument.\n",
        "# This method splits the input text into chunks according to the chunk_size and chunk_overlap parameters specified\n",
        "# when the r_splitter object was created.\n",
        "r_splitter = CharacterTextSplitter(\n",
        "    chunk_size=250,\n",
        "    chunk_overlap=25\n",
        ")\n",
        "\n",
        "r_splitter.split_text(some_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efa10d54-34a4-46f4-a84b-320041e3835c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:15:46.276826Z",
          "start_time": "2024-04-18T10:15:44.926933Z"
        },
        "id": "efa10d54-34a4-46f4-a84b-320041e3835c"
      },
      "outputs": [],
      "source": [
        "# Testing on PDF\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"https://www.developer.tech.gov.sg/products/collections/data-science-and-artificial-intelligence/playbooks/prompt-engineering-playbook-beta-v3.pdf\")\n",
        "pages = loader.load()\n",
        "\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50,\n",
        "    length_function=count_tokens\n",
        ")\n",
        "\n",
        "\n",
        "splitted_documents = text_splitter.split_documents(pages)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6c14b60-9ac7-494e-937e-7cd1e758948c",
      "metadata": {
        "id": "e6c14b60-9ac7-494e-937e-7cd1e758948c"
      },
      "source": [
        "> 💡 Explanation\n",
        "\n",
        "- **Separators**:\n",
        "    - The separators parameter is a list of strings that the algorithm will use to split the text.\n",
        "    - The algorithm will try to split the text using the first separator in the list.\n",
        "    - If the resulting chunks are still larger than the chunk_size, it will try to split them further using the next separator in the list, and so on.\n",
        "    - This process continues until all chunks are smaller than the chunk_size or until all separators have been used.\n",
        "- **Chunk Size**:\n",
        "    - The chunk_size parameter is the maximum size for each chunk of text.\n",
        "    - If after using all separators, there are still chunks that are larger than the chunk_size, the algorithm will split these chunks at the chunk_size character, regardless of where this falls in the text.\n",
        "- **Chunk Overlap**:\n",
        "    - The chunk_overlap parameter determines how many characters from the end of one chunk should be repeated at the start of the next chunk.\n",
        "    - This can be useful to provide context when processing each chunk independently.\n",
        "- **Length Function**:\n",
        "    - The length_function parameter is a function that calculates the ‘length’ of a chunk.\n",
        "    - This could be a simple function like len (which counts characters), or a more complex function like count_tokens (which counts words or tokens).\n",
        "\n",
        "`RecursiveCharacterTextSplitter` will first try to split by the separators. If the resulting chunks are still too large, it will then split them further until they are smaller than the chunk_size. The chunk_overlap is applied after all splitting is done. The length_function is used throughout this process to measure the size of the chunks. It’s important to note that the separators are tried in the order they are given in the list, and the algorithm will always try to split by separators before resorting to splitting by chunk_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1205544b-a581-43e5-85e0-ac7e477f8ad7",
      "metadata": {
        "id": "1205544b-a581-43e5-85e0-ac7e477f8ad7"
      },
      "outputs": [],
      "source": [
        "len(splitted_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a068f2cd-e94e-4288-b01f-a7c20938bfd4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-18T10:15:46.989328Z",
          "start_time": "2024-04-18T10:15:46.985814Z"
        },
        "id": "a068f2cd-e94e-4288-b01f-a7c20938bfd4"
      },
      "outputs": [],
      "source": [
        "splitted_documents[15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb0379d5-7c0e-4af1-9375-f9ab9c1d7260",
      "metadata": {
        "id": "bb0379d5-7c0e-4af1-9375-f9ab9c1d7260"
      },
      "outputs": [],
      "source": [
        "splitted_documents[16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "283a4787-6719-4cc2-8536-ae3f4b7975c1",
      "metadata": {
        "id": "283a4787-6719-4cc2-8536-ae3f4b7975c1"
      },
      "outputs": [],
      "source": [
        "splitted_documents[17]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef7efabf-f41e-4a98-81ea-fb8312ed9063",
      "metadata": {
        "id": "ef7efabf-f41e-4a98-81ea-fb8312ed9063"
      },
      "source": [
        "<br>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "359280fe-35d5-4282-8e1a-83a4a70b081b",
      "metadata": {
        "id": "359280fe-35d5-4282-8e1a-83a4a70b081b"
      },
      "source": [
        "### Embedding & Vectorstores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6d3ab60-7147-4404-a734-47641f3e9184",
      "metadata": {
        "id": "d6d3ab60-7147-4404-a734-47641f3e9184"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16aab217-4bdb-4a2f-9153-bacbc531f68e",
      "metadata": {
        "id": "16aab217-4bdb-4a2f-9153-bacbc531f68e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
        "db = Chroma.from_documents(splitted_documents, embeddings_model, persist_directory=\"./chroma_db\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a71b979a-2d25-4bfd-8dfa-d323fa1f110b",
      "metadata": {
        "id": "a71b979a-2d25-4bfd-8dfa-d323fa1f110b"
      },
      "outputs": [],
      "source": [
        "print(db._collection.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b449b7e2-831e-4918-a1b5-685efdadbb08",
      "metadata": {
        "id": "b449b7e2-831e-4918-a1b5-685efdadbb08"
      },
      "source": [
        "<br>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61d7566a-07c9-48cb-b853-4441b97d437a",
      "metadata": {
        "id": "61d7566a-07c9-48cb-b853-4441b97d437a"
      },
      "source": [
        "### Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70df7963-a34f-4ad3-89fd-faa44efa0c15",
      "metadata": {
        "id": "70df7963-a34f-4ad3-89fd-faa44efa0c15"
      },
      "source": [
        "![](https://d27l3jncscxhbx.cloudfront.net/lib/media/img-20240421143642415.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0bbed5d-5908-4765-bcd7-77da82a56190",
      "metadata": {
        "id": "a0bbed5d-5908-4765-bcd7-77da82a56190"
      },
      "source": [
        " ### Basic Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63b3537b-90eb-4c10-9aaa-d78bc8b20ff1",
      "metadata": {
        "id": "63b3537b-90eb-4c10-9aaa-d78bc8b20ff1"
      },
      "outputs": [],
      "source": [
        "db.similarity_search('Zero Shot', k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5854439-85e1-4774-8074-be1dd7397dae",
      "metadata": {
        "id": "a5854439-85e1-4774-8074-be1dd7397dae",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "db.similarity_search_with_relevance_scores('Zero Shot', k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56b57228-4a9f-4a71-a086-ee705e2df3e5",
      "metadata": {
        "id": "56b57228-4a9f-4a71-a086-ee705e2df3e5"
      },
      "source": [
        "### Question & Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "438021ce-e167-4e8e-8630-2c5915296d43",
      "metadata": {
        "id": "438021ce-e167-4e8e-8630-2c5915296d43"
      },
      "source": [
        "![](https://d27l3jncscxhbx.cloudfront.net/lib/media/img-20240421150029496.png)\n",
        "\n",
        "- Multiple relevant documents have been retrieved from the vector store\n",
        "- Potentially compress the relevant splits to fit into the LLM context\n",
        "- Send the information along with our question to an LLM to select and format an answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3260a3-c6e8-4e17-8ec8-0cb09bfb0aef",
      "metadata": {
        "id": "7e3260a3-c6e8-4e17-8ec8-0cb09bfb0aef"
      },
      "source": [
        "#### RetrievalQA Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "697e341b-933c-4661-a793-3d113e82cb73",
      "metadata": {
        "id": "697e341b-933c-4661-a793-3d113e82cb73"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc928321-6028-4a19-8ff3-3dd996f23204",
      "metadata": {
        "id": "cc928321-6028-4a19-8ff3-3dd996f23204"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a02b187-c4c7-4e3a-a343-6a006e188bee",
      "metadata": {
        "id": "2a02b187-c4c7-4e3a-a343-6a006e188bee"
      },
      "outputs": [],
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    ChatOpenAI(model='gpt-3.5-turbo'),\n",
        "    retriever=db.as_retriever(k=20)\n",
        ")\n",
        "\n",
        "qa_chain.invoke(\"Why LLM hallucinate?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "807dc747-ebfd-4da1-bd91-527eac92d675",
      "metadata": {
        "id": "807dc747-ebfd-4da1-bd91-527eac92d675"
      },
      "source": [
        "#### With Custom Q&A Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c739ea39-97fe-426c-b6e6-02c270f9a1f4",
      "metadata": {
        "id": "c739ea39-97fe-426c-b6e6-02c270f9a1f4"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Build prompt\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
        "\n",
        "# Run chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    ChatOpenAI(model='gpt-3.5-turbo'),\n",
        "    retriever=db.as_retriever(),\n",
        "    return_source_documents=True, # Make inspection of document possible\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "122eeebd-b821-4713-af46-d3174dc1c0d3",
      "metadata": {
        "id": "122eeebd-b821-4713-af46-d3174dc1c0d3"
      },
      "outputs": [],
      "source": [
        "qa_chain.invoke(\"Why LLM hallucinate?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kK2U2qRnX6ul",
      "metadata": {
        "id": "kK2U2qRnX6ul"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "aicamp-python3.11.6",
      "language": "python",
      "name": "aicamp-python3.11.6"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}